{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkOGylEB9JBf"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "You have to build Retrieval-Augmented Generation (RAG) Model for QA Bot\n",
        "\n",
        "Develop a Retrieval-Augmented Generation (RAG) model for a Question Answering (QA) bot for a business. Use a vector database like Pinecone DB or Chroma DB and a generative model like Cohere API or OpenAI. The QA bot should be able to retrieve relevant information from a dataset and generate coherent answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC8g3_-v9q0J"
      },
      "source": [
        "# Import all the important dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "fNd2oGliwXYm"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U langchain-community langchain openai chromadb langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QudofKQK93Yu"
      },
      "source": [
        "# From langchain framework import neccessary class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YQ13S6LnwXV_"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "\n",
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow\n",
        "\n",
        "![Alt text](image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcFM1M__-C4X"
      },
      "source": [
        "# From PDF_Docs directory loading and reading the PDF document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLtRekfjwXSl",
        "outputId": "4e65bdf1-ac62-4ce9-c69d-bd2b3c2c8db1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 68 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 78 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 88 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 32 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 13 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 15 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 135 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "loader = PyPDFDirectoryLoader(\"PDF_Docs\")\n",
        "documents = loader.load()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvuNa6Cv-RAO"
      },
      "source": [
        "## Splitting entire documents into small small chunks so that LLM can context them as input token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJSmAGS_wXQh",
        "outputId": "4d356cd0-10d1-48cc-a1fa-6aefdb6db739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter  = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "text_chunks = text_splitter.split_documents(documents)\n",
        "len(text_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgSbbN400Bru",
        "outputId": "14707226-1a4a-46ac-d456-d3549f69a23a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(text_chunks[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "l6nHT_XI0SKP",
        "outputId": "ad17453c-829f-4c18-e5dc-6ce7519a6bf2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'SQL in DS  DB Schema It represent how the data is organised & provides informa4on about the rela4onships between the tables in a given database. Table Schema: Represent metadata of a table. 1. A=ributes (columns) of table 2. Data type of a=ributes: i) Numeric (like student_id, age, salary, weight, height, etc.) ii) String Char/Var char (Name) iii) Date (Date/4mestamp) Char is Ô¨Åxed length string and var char is a variable length string.  Primary Key : A column that can be used to uniquely iden4fy each row in the table. Constraint: Unique + Not Null \\n Foreign Key: A column in a table that refers to the primary key in another table. Foreign key link together tables in a rela4onal database.'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_chunks[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avTAX3Z4wXL3",
        "outputId": "a9a9c3f7-cc1c-4346-a19c-0b014fc99a1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "695"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_chunks[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "7gDiWxdwwXIp",
        "outputId": "9b31743b-7585-415c-8445-d1d5b8d42971"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.\n",
              "\n",
              "Example:\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_core.documents import Document\n",
              "\n",
              "        document = Document(\n",
              "            page_content=&quot;Hello, world!&quot;,\n",
              "            metadata={&quot;source&quot;: &quot;https://example.com&quot;}\n",
              "        )</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 257);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "langchain_core.documents.base.Document"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(text_chunks[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UR_Rhls-gVF"
      },
      "source": [
        "## Use OpenAI Embedding for text embedding by using OpenAI API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaNH5Mag_H18",
        "outputId": "0fa2f21c-0974-44a1-c14e-33ff87da085d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-8b3a747290ab>:8: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1536\n"
          ]
        }
      ],
      "source": [
        "# Use getpass to securely input your OpenAI API key\n",
        "api_key = getpass('Enter your OpenAI API key: ')\n",
        "\n",
        "# Set it as an environment variable\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "# Initialize OpenAI embeddings using the API key from environment variable\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
        "\n",
        "# Example query\n",
        "result = embeddings.embed_query(\"How are you!\")\n",
        "\n",
        "# Check the length of the result (embedding vector)\n",
        "print(len(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmNOmK9VAEBT"
      },
      "source": [
        "## Using Chroma vector databse to store text chunks into text embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mh3ZW26p0ngE"
      },
      "outputs": [],
      "source": [
        "vectordb = Chroma.from_documents(documents=text_chunks, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2cZYRBD1qze",
        "outputId": "8b53f8f3-3f7a-42f2-e933-eb5de03a2167"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "166"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vectordb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Boh61AAoFj"
      },
      "source": [
        "## Finding the top 2 similar text document from the vector dataabse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xKUIZoqe1OQi"
      },
      "outputs": [],
      "source": [
        "query = vectordb.similarity_search(query=\"What is the difference between positional encoding and layer normalization?\", k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLyv-Inq1Rua",
        "outputId": "7705349b-a71b-45a5-e9ab-54156628886e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 25, 'source': 'PDF_Docs/Document1.pdf'}, page_content='When using batch normaliza7on on sequences with padding, the calculated mean and variance can be skewed because padding values distort the true representa7on of the data. Padding is added to make input sequences equal in length, but it introduces ar7Ô¨Åcial values that aÔ¨Äect the accuracy of the mean and variance. To address this issue, layer normaliza7on is used instead. Layer normalisa7on normalizes across the features (or rows) within each individual sequence, rather than across the batch (or columns), ensuring that padding doesn‚Äôt interfere with the normalisa7on process and providing a more accurate representa7on of the data. Conclusion: Posi3onal Encoding The technique of posi7onal encoding is employed in transformer models to provide the model with informa7on regarding the word order in a sequence. Because self-a>en7on does not naturally follow a sequence, posi7onal encodings are appended to the word embeddings. These encodings enable the model to comprehend the sequence structure'),\n",
              " Document(metadata={'page': 21, 'source': 'PDF_Docs/Document1.pdf'}, page_content='In original paper the each word embedding and posi7onal encoding vector is of 512 dimension. Layer Normalisa3on Before understanding layer normalisa7on, let us understand batch normalisa7on. Batch normalisa7on is a technique which is use to normalise across the bacth dimension or acorss the column and is highly eÔ¨Äec7ve in ANN and CNN where batch size is Ô¨Åx. It is apply to input layer and the output of hidden layer.')]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRGsPIj_BnIC"
      },
      "source": [
        "## Top 3 most similar documents/text from the database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbDlREgg2_un",
        "outputId": "490ba6a1-f1cd-4583-aae2-e99be0975623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result 1: Top Interview Ques3ons for DS  In this ar4cle, we‚Äôll explore the top ques4ons commonly asked in data science interviews, breaking them down into simple, easy-to-understand explana4ons. Q.1 Explain the bias-variance tradeoÔ¨Ä. \n",
            "Model Complexity Bias and variance are inversely propor4onal to each other. When bias increases variance decreases. Therefore, we need to Ô¨Ånd a balance trade between the two. Q2. What is overÔ¨ÅTng, and how can you prevent it?\n",
            "Metadata: {'page': 9, 'source': 'PDF_Docs/Document2.pdf'}\n",
            "Result 2: Sta$s$cs and Probability needed in DS  In this blog, we‚Äôll provide a concise overview of the essen7al sta7s7cs and probability concepts needed for a data science role. Central limit Theorem : The distribu7on of sample means is Gaussian, no ma>er what the shape of the original distribu7on is. Assump7ons: popula7on mean and standard devia7on should be Ô¨Ånite and sample size >=30  How to prove CLT in python: sample_30 = [df['income'].sample(30).mean() for i in range(10000)] sns.histplot(sample_30, kde=True) sns.histplot(df['income'], kde = True) Hypothesis Tes3ng: A hypothesis test is a sta7s7cal method used to make inferences or predic7on or decisions about a popula7on based on sample data. ‚Ä¢ Null Hypothesis (H‚ÇÄ): The default assump7on or statement being tested. It usually suggests that there is no eÔ¨Äect, no diÔ¨Äerence, or no rela7onship between variables. Example: 1. The accused is innocent 2. The average height of men in a popula7on is 70 inches. ‚Ä¢ Alterna3ve Hypothesis (H‚ÇÅ or Ha): The\n",
            "Metadata: {'page': 0, 'source': 'PDF_Docs/Document1.pdf'}\n",
            "Result 3: E.g. 1. Suppose a hospital experiences an avg. of 2 births/hr. Calculate prob. of experiencing 0, 1, 2, 3, birth in a given hr. 2. Imagine we collect the data of all football matches played. It is found that in a 90 min match the avg. goals are 2.5. Calculate the prob. of ge¬Çng 1 goal in last 30 mins?  3. A city sees 3 accidents per day on average. Find the prob. that there will be 5 or fewer accidents tomorrow?  4. There are 80 students. Each one of them has 0.015 prob. of forge¬Çng thier lunch on any given day. Calculate avg. or expected no of students who forget lunch in the class? Prob. that exactly 3 of them will forget their lunch today? Condi3onal Probability: Prob. of an event occurring given that another event has already occurred. Bayes‚Äô Theorem It provides a way to update the prob. of an event based on new evidence. It related the condi7onal prob. of 2 events in both direc7on & incorporate prior knowledge. Bayes‚Äô Theorem is build upon the concept of condi7onal prob. i.e.\n",
            "Metadata: {'page': 14, 'source': 'PDF_Docs/Document1.pdf'}\n"
          ]
        }
      ],
      "source": [
        "query1 = \"How much probability and statistic require to crack data science interview?\"\n",
        "\n",
        "results = vectordb.similarity_search(query1, k=3)\n",
        "\n",
        "# Display results\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Result {i+1}: {result.page_content}\")\n",
        "    print(f\"Metadata: {result.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UstYPg0ZAZgw"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWfKYVvtBwjj"
      },
      "source": [
        "## Creates a Retrieval-Augmented Generation (RAG) pipeline for answering questions using a large language model (LLM) and a vector database to retrieve relevant documents or text chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "MtAUrd5f3fiJ",
        "outputId": "d082142f-d394-4061-cc40-e5e78639cac1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-17-136cfbb0217b>:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  rag_chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
            "<ipython-input-17-136cfbb0217b>:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  rag_chain.run(query1)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' This document seems to be discussing the use of LSTM encoder and decoder architecture for text summarization, specifically focusing on the self-attention mechanism for representing words and finding similarity between them using dot product. It also mentions the use of linear transformation with different matrices during the training process.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=vectordb.as_retriever())\n",
        "rag_chain.run(query1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LBzXrkqCU9W"
      },
      "source": [
        "- LLM (OpenAI): For generating the final response.\n",
        "- Vector Database (vectordb): To store and retrieve text embeddings based on similarity.\n",
        "- Retriever: A mechanism that retrieves relevant chunks or documents for the LLM to base its answer on.\n",
        "- Chain Type (\"stuff\"): A method of handling the retrieved documents before generating an answer. Here, it simply concatenates all the retrieved documents."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
